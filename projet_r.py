import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_curve, roc_auc_score
# Charger les donn√©es
df = pd.read_excel("C:/INSEEDS/ORIEN.xlsx")

# Aper√ßu rapide
print(df.shape)
print(df.columns)
df.head()

# Liste des variables √† examiner
colonnes = [
    '√¢ge', 'Sexe', 'ville_post_bac', 'Profession_pere', 'profession_mere',
    'fili√®re', 'motif_fili√®re', 'choix_fili√®re', 'preparation_choix',
    'Connaissance_fili√®re', 'conseil_par_pro', 'influence_choix',
    'acc√®s_plateforme', 'journ√©es_orientation', 'satisfaction_fili√®re',
    'niveau_√©tude', 'dipl√¥me', 'employabilite', 'reconversion',
    'referiez_m√™me_choix', 'bon_choix_fili√®re'
]

# Affiche les modalit√©s de chaque variable
for col in colonnes:
    print(f"--- {col} ---")
    print(df[col].unique())
    print()


import pandas as pd
from sklearn.preprocessing import LabelEncoder

# 1. Nettoyage manuel des fautes et doublons
df['ville_post_bac'] = df['ville_post_bac'].str.strip().str.title()
df['acc√®s_plateforme'] = df['acc√®s_plateforme'].str.capitalize()

# Harmoniser les accents ou apostrophes mal encod√©s
df['fili√®re'] = df['fili√®re'].str.strip().str.title().replace({
    "Informatique D√©veloppeur D‚ÄôApplications": "Informatique D√©veloppeur D'Applications",
    "L‚ÄôAnglais": "Anglais"
})
df['motif_fili√®re'] = df['motif_fili√®re'].replace({
    "P D√©bauch√©s professionels": "D√©bauch√©s professionels"
})
df['journ√©es_orientation'] = df['journ√©es_orientation'].replace({
    "Oui, j'y ai particip√©": "Oui"
})
df['acc√®s_plateforme'] = df['acc√®s_plateforme'].replace({'oui': 'Oui'})

# 2. Encodage binaire Oui/Non
colonnes_binaires = [
    'preparation_choix', 'Connaissance_fili√®re', 'conseil_par_pro',
    'acc√®s_plateforme', 'satisfaction_fili√®re', 'dipl√¥me', 'employabilite',
    'reconversion', 'referiez_m√™me_choix', 'bon_choix_fili√®re'
]

for col in colonnes_binaires:
    df[col] = df[col].map({'Oui': 1, 'Non': 0, 'Un peu': 0.5})

# 3. Conversion de l'√¢ge en num√©rique
df['√¢ge'] = pd.to_numeric(df['√¢ge'], errors='coerce')

# 4. Variables cat√©gorielles √† encoder
cat_vars = [
    'Sexe', 'ville_post_bac', 'Profession_pere', 'profession_mere',
    'fili√®re', 'motif_fili√®re', 'choix_fili√®re', 'influence_choix',
    'niveau_√©tude', 'journ√©es_orientation'
]

# Encodage LabelEncoder pour les variables cat√©gorielles
le_dict = {}
for col in cat_vars:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    le_dict[col] = le  # stocker si besoin pour d√©coder dans l'app

# 5. V√©rification finale
print(df.info())
print(df.head())

# Supprimer les variables avec tr√®s peu de variation (presque constantes)
from sklearn.feature_selection import VarianceThreshold

# Exclure la cible temporairement
X_temp = df.drop(columns=["bon_choix_fili√®re"])
selector = VarianceThreshold(threshold=0.01)  # < 1% de variance
selector.fit(X_temp)

# Conserver seulement les variables utiles
columns_kept = X_temp.columns[selector.get_support()]
print("Variables avec assez de variance :", list(columns_kept))

import seaborn as sns
import matplotlib.pyplot as plt

# On recolle la cible temporairement
df_corr = df.copy()

# Calcul des corr√©lations avec la variable cible
correlations = df_corr.corr()['bon_choix_fili√®re'].drop('bon_choix_fili√®re').sort_values(key=abs, ascending=False)

# Affichage des meilleures corr√©lations
print("Corr√©lations avec bon_choix_fili√®re :")
print(correlations)

# Visualisation
plt.figure(figsize=(10,6))
sns.barplot(x=correlations.values, y=correlations.index)
plt.title("Corr√©lation des variables avec bon_choix_fili√®re")
plt.show()

from sklearn.ensemble import RandomForestClassifier

X = df.drop(columns=["bon_choix_fili√®re"])
y = df["bon_choix_fili√®re"]

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X, y)

importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
print("Importance des variables :")
print(importances)

# Graphique
importances.plot(kind='barh', figsize=(10, 8))
plt.title("Importance des variables (Random Forest)")
plt.gca().invert_yaxis()
plt.show()


variables_utiles = [
    'preparation_choix', 'Connaissance_fili√®re', 'conseil_par_pro',
    'acc√®s_plateforme', 'satisfaction_fili√®re', 'dipl√¥me', 'employabilite',
    'reconversion', 'referiez_m√™me_choix'
]

X = df[variables_utiles]
y = df['bon_choix_fili√®re']  # cible


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import pandas as pd

# ‚ö†Ô∏è √âtape 1 : r√©√©quilibrage avec SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# ‚öñÔ∏è √âtape 2 : split en 3 jeux (train, val, test)
X_temp, X_test, y_temp, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.3, stratify=y_resampled, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42
)
# (‚Üí 52.5% train, 17.5% val, 30% test)

# üß† √âtape 3 : mod√®les avec pond√©ration (si applicable)
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, penalty='l2', C=0.1, random_state=42, class_weight='balanced'),
    "Random Forest": RandomForestClassifier(n_estimators=50, max_depth=2, min_samples_leaf=5, random_state=42, class_weight='balanced'),
    "Gradient Boosting": GradientBoostingClassifier(
        n_estimators=50, max_depth=2, learning_rate=0.1, subsample=0.8, random_state=42
    ),
    "KNN": KNeighborsClassifier(n_neighbors=3, weights='distance')
}

# üîÅ √âtape 4 : entra√Ænement + √©valuation
results = []
for name, model in models.items():
    if name == "XGBoost":
        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)
    else:
        model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results.append({
        'Model': name,
        'Accuracy': acc,
        'F1-score': f1,
        'Best Iteration': getattr(model, 'best_iteration_', 'N/A')
    })

# üìä √âtape 5 : affichage des r√©sultats
results_df = pd.DataFrame(results).sort_values('F1-score', ascending=False)
print("R√âSULTATS COMPARATIFS:")
print(results_df.to_string(index=False))

# üåü √âtape 6 : Importance des variables
print("\nIMPORTANCE DES VARIABLES:")
for name in ["Random Forest", "XGBoost", "Gradient Boosting"]:
    if name in models:
        print(f"\n{name}:")
        importance = pd.Series(models[name].feature_importances_, index=X.columns)
        print(importance.sort_values(ascending=False).head(5))

# üßæ √âtape 7 : √©valuation d√©taill√©e
print("\n√âVALUATION D√âTAILL√âE PAR MOD√àLE :\n")
for name, model in models.items():
    print(f"--- {name} ---")
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    print("Matrice de confusion :")
    print(cm)
    total = cm.sum()
    correct = cm.diagonal().sum()
    erreurs = total - correct
    taux_erreur = erreurs / total
    print(f"Taux de mauvais classement : {taux_erreur:.2%}")
    print("\nClassification report :")
    print(classification_report(y_test, y_pred))
    print("\n")

# üîé Trouver le meilleur mod√®le
best_model_name = results_df.iloc[0]['Model']
print(f"\nüåü Meilleur mod√®le selon F1-score : {best_model_name}")

# üîÅ R√©cup√©rer l'objet du mod√®le
best_model = models[best_model_name]

# üîÆ Pr√©dictions
y_best_pred = best_model.predict(X_test)

# üßæ Matrice de confusion
cm = confusion_matrix(y_test, y_best_pred)
print("Matrice de confusion :")
print(cm)

# ‚ö†Ô∏è Taux de mauvais classement
total = cm.sum()
correct = cm.diagonal().sum()
erreurs = total - correct
taux_erreur = erreurs / total
print(f"Taux de mauvais classement : {taux_erreur:.2%}")

# üìå Rapport complet
print("\nClassification report :")
print(classification_report(y_test, y_best_pred))
import joblib

# üîê Sauvegarde dans le dossier choisi
chemin_sauvegarde = r"C:\INSEEDS\PROJET AFTER BAC\random_forest_orientation.pkl"
joblib.dump(best_model, chemin_sauvegarde)

print(f"‚úÖ Mod√®le sauvegard√© avec succ√®s dans : {chemin_sauvegarde}")


#___________________________________________


import streamlit as st
import joblib
import pandas as pd

# üîê Charger le meilleur mod√®le
model = joblib.load(r"C:\INSEEDS\PROJET AFTER BAC\random_forest_orientation.pkl")

# üñºÔ∏è Interface
st.set_page_config(page_title="Orientation Post-Bac", layout="centered")
st.markdown("<h1 style='color: #004aad;'>üîç Pr√©diction de bon/mauvais choix de fili√®re</h1>", unsafe_allow_html=True)
st.markdown("<h4>üí° Remplissez les caract√©ristiques de l'√©tudiant :</h4>", unsafe_allow_html=True)
kb = pd.read_excel("C:/INSEEDS/ORIEN.xlsx")
# üéõÔ∏è Menus d√©roulants
villes = sorted(kb['ville_post_bac'].unique())
ville = st.selectbox("Dans quelle ville Avez vous eu votre Bac?", options=villes)
fili√®re= st.text_input("quelle fili√®re aimeriez vous faire? ")
motif_fili√®res = sorted(kb['motif_fili√®re'].unique())
motif_fili√®re = st.selectbox("pourquoi cette fili√®re?", options=motif_fili√®res)
preparation_choix = st.selectbox("üß† Avez-vous pr√©par√© ce choix ?", ["Oui", "Non", "Un peu"])
Connaissance_fili√®re = st.selectbox("üìñ connaissez vous bien de la fili√®re", ["Oui", "Non", "Un peu"])
conseil_par_pro = st.selectbox("üëî Avez-vous √©t√© conseill√© par un professionnel ?", ["Oui", "Non"])
acc√®s_plateforme = st.selectbox("üåê Avez-vous utilis√© une plateforme d‚Äôorientation ?", ["Oui", "Non"])
satisfaction_fili√®re = st.selectbox("üòä Seriez-vous satisfait(e) de la fili√®re ?", ["Oui", "Non"])
dipl√¥me = st.selectbox("üéì Avez-vous un dipl√¥me ?", ["Oui", "Non"])
employabilite = st.selectbox("üíº Pensez-vous que vous serez  ou √™tes employable ?", ["Oui", "Non"])
reconversion = st.selectbox("üîÑ Souhaitez-vous vous reconvertir ?", ["Oui", "Non"])
referiez_m√™me_choix = st.selectbox("üîÅ Referiez-vous le m√™me choix ?", ["Oui", "Non"])


# üéØ Pr√©diction au clic
if st.button("üéØ Pr√©dire le choix"):

    # üßæ Donn√©es utilisateur
    input_data = pd.DataFrame({
        'preparation_choix': [preparation_choix],
        'Connaissance_fili√®re': [Connaissance_fili√®re],
        'conseil_par_pro': [conseil_par_pro],
        'acc√®s_plateforme': [acc√®s_plateforme],
        'satisfaction_fili√®re': [satisfaction_fili√®re],
        'dipl√¥me': [dipl√¥me],
        'employabilite': [employabilite],
        'reconversion': [reconversion],
        'referiez_m√™me_choix': [referiez_m√™me_choix]
    })

    # üîÅ Encodage des valeurs
    conversion = {
        "Oui": 1, "Non": 0, "Un peu": 0.5
    }

    input_data = input_data.applymap(lambda val: conversion.get(val, val))  # s√©curise les valeurs non mapp√©es

    # üö® V√©rification
    if input_data.isnull().any().any():
        st.error("‚ö†Ô∏è Certaines r√©ponses ne sont pas reconnues. V√©rifie les valeurs ou √©largis le mapping.")
        st.write("Donn√©es re√ßues :", input_data)
    else:
        # üîÆ Pr√©diction
        prediction = model.predict(input_data)[0]
        proba = model.predict_proba(input_data)[0]

        # üì¢ Affichage du r√©sultat
        if prediction == 0:
            st.error(f"‚ùå Risque √©lev√© : Mauvais choix possible.\nüîª Score : {proba[0]*100:.2f}%")
        else:
            st.success(f"‚úÖ Bon choix d√©tect√© !\nüü¢ Score : {proba[1]*100:.2f}%")

        # üìä Graphique
        st.markdown("### üìä Score de pr√©diction :")
        st.bar_chart({"Bon choix": [proba[1]*100], "Mauvais choix": [proba[0]*100]})


























