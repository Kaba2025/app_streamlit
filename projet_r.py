import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_curve, roc_auc_score
# Charger les donnÃ©es
df = pd.read_excel("C:/INSEEDS/ORIEN.xlsx")

# AperÃ§u rapide
print(df.shape)
print(df.columns)
df.head()

# Liste des variables Ã  examiner
colonnes = [
    'Ã¢ge', 'Sexe', 'ville_post_bac', 'Profession_pere', 'profession_mere',
    'filiÃ¨re', 'motif_filiÃ¨re', 'choix_filiÃ¨re', 'preparation_choix',
    'Connaissance_filiÃ¨re', 'conseil_par_pro', 'influence_choix',
    'accÃ¨s_plateforme', 'journÃ©es_orientation', 'satisfaction_filiÃ¨re',
    'niveau_Ã©tude', 'diplÃ´me', 'employabilite', 'reconversion',
    'referiez_mÃªme_choix', 'bon_choix_filiÃ¨re'
]

# Affiche les modalitÃ©s de chaque variable
for col in colonnes:
    print(f"--- {col} ---")
    print(df[col].unique())
    print()


import pandas as pd
from sklearn.preprocessing import LabelEncoder

# 1. Nettoyage manuel des fautes et doublons
df['ville_post_bac'] = df['ville_post_bac'].str.strip().str.title()
df['accÃ¨s_plateforme'] = df['accÃ¨s_plateforme'].str.capitalize()

# Harmoniser les accents ou apostrophes mal encodÃ©s
df['filiÃ¨re'] = df['filiÃ¨re'].str.strip().str.title().replace({
    "Informatique DÃ©veloppeur Dâ€™Applications": "Informatique DÃ©veloppeur D'Applications",
    "Lâ€™Anglais": "Anglais"
})
df['motif_filiÃ¨re'] = df['motif_filiÃ¨re'].replace({
    "P DÃ©bauchÃ©s professionels": "DÃ©bauchÃ©s professionels"
})
df['journÃ©es_orientation'] = df['journÃ©es_orientation'].replace({
    "Oui, j'y ai participÃ©": "Oui"
})
df['accÃ¨s_plateforme'] = df['accÃ¨s_plateforme'].replace({'oui': 'Oui'})

# 2. Encodage binaire Oui/Non
colonnes_binaires = [
    'preparation_choix', 'Connaissance_filiÃ¨re', 'conseil_par_pro',
    'accÃ¨s_plateforme', 'satisfaction_filiÃ¨re', 'diplÃ´me', 'employabilite',
    'reconversion', 'referiez_mÃªme_choix', 'bon_choix_filiÃ¨re'
]

for col in colonnes_binaires:
    df[col] = df[col].map({'Oui': 1, 'Non': 0, 'Un peu': 0.5})

# 3. Conversion de l'Ã¢ge en numÃ©rique
df['Ã¢ge'] = pd.to_numeric(df['Ã¢ge'], errors='coerce')

# 4. Variables catÃ©gorielles Ã  encoder
cat_vars = [
    'Sexe', 'ville_post_bac', 'Profession_pere', 'profession_mere',
    'filiÃ¨re', 'motif_filiÃ¨re', 'choix_filiÃ¨re', 'influence_choix',
    'niveau_Ã©tude', 'journÃ©es_orientation'
]

# Encodage LabelEncoder pour les variables catÃ©gorielles
le_dict = {}
for col in cat_vars:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    le_dict[col] = le  # stocker si besoin pour dÃ©coder dans l'app

# 5. VÃ©rification finale
print(df.info())
print(df.head())

# Supprimer les variables avec trÃ¨s peu de variation (presque constantes)
from sklearn.feature_selection import VarianceThreshold

# Exclure la cible temporairement
X_temp = df.drop(columns=["bon_choix_filiÃ¨re"])
selector = VarianceThreshold(threshold=0.01)  # < 1% de variance
selector.fit(X_temp)

# Conserver seulement les variables utiles
columns_kept = X_temp.columns[selector.get_support()]
print("Variables avec assez de variance :", list(columns_kept))

import seaborn as sns
import matplotlib.pyplot as plt

# On recolle la cible temporairement
df_corr = df.copy()

# Calcul des corrÃ©lations avec la variable cible
correlations = df_corr.corr()['bon_choix_filiÃ¨re'].drop('bon_choix_filiÃ¨re').sort_values(key=abs, ascending=False)

# Affichage des meilleures corrÃ©lations
print("CorrÃ©lations avec bon_choix_filiÃ¨re :")
print(correlations)

# Visualisation
plt.figure(figsize=(10,6))
sns.barplot(x=correlations.values, y=correlations.index)
plt.title("CorrÃ©lation des variables avec bon_choix_filiÃ¨re")
plt.show()

from sklearn.ensemble import RandomForestClassifier

X = df.drop(columns=["bon_choix_filiÃ¨re"])
y = df["bon_choix_filiÃ¨re"]

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X, y)

importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
print("Importance des variables :")
print(importances)

# Graphique
importances.plot(kind='barh', figsize=(10, 8))
plt.title("Importance des variables (Random Forest)")
plt.gca().invert_yaxis()
plt.show()


variables_utiles = [
    'preparation_choix', 'Connaissance_filiÃ¨re', 'conseil_par_pro',
    'accÃ¨s_plateforme', 'satisfaction_filiÃ¨re', 'diplÃ´me', 'employabilite',
    'reconversion', 'referiez_mÃªme_choix'
]

X = df[variables_utiles]
y = df['bon_choix_filiÃ¨re']  # cible


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import pandas as pd

# âš ï¸ Ã‰tape 1 : rÃ©Ã©quilibrage avec SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# âš–ï¸ Ã‰tape 2 : split en 3 jeux (train, val, test)
X_temp, X_test, y_temp, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.3, stratify=y_resampled, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42
)
# (â†’ 52.5% train, 17.5% val, 30% test)

# ğŸ§  Ã‰tape 3 : modÃ¨les avec pondÃ©ration (si applicable)
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, penalty='l2', C=0.1, random_state=42, class_weight='balanced'),
    "Random Forest": RandomForestClassifier(n_estimators=50, max_depth=2, min_samples_leaf=5, random_state=42, class_weight='balanced'),
    "Gradient Boosting": GradientBoostingClassifier(
        n_estimators=50, max_depth=2, learning_rate=0.1, subsample=0.8, random_state=42
    ),
    "KNN": KNeighborsClassifier(n_neighbors=3, weights='distance')
}

# ğŸ” Ã‰tape 4 : entraÃ®nement + Ã©valuation
results = []
for name, model in models.items():
    if name == "XGBoost":
        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=False)
    else:
        model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results.append({
        'Model': name,
        'Accuracy': acc,
        'F1-score': f1,
        'Best Iteration': getattr(model, 'best_iteration_', 'N/A')
    })

# ğŸ“Š Ã‰tape 5 : affichage des rÃ©sultats
results_df = pd.DataFrame(results).sort_values('F1-score', ascending=False)
print("RÃ‰SULTATS COMPARATIFS:")
print(results_df.to_string(index=False))

# ğŸŒŸ Ã‰tape 6 : Importance des variables
print("\nIMPORTANCE DES VARIABLES:")
for name in ["Random Forest", "XGBoost", "Gradient Boosting"]:
    if name in models:
        print(f"\n{name}:")
        importance = pd.Series(models[name].feature_importances_, index=X.columns)
        print(importance.sort_values(ascending=False).head(5))

# ğŸ§¾ Ã‰tape 7 : Ã©valuation dÃ©taillÃ©e
print("\nÃ‰VALUATION DÃ‰TAILLÃ‰E PAR MODÃˆLE :\n")
for name, model in models.items():
    print(f"--- {name} ---")
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    print("Matrice de confusion :")
    print(cm)
    total = cm.sum()
    correct = cm.diagonal().sum()
    erreurs = total - correct
    taux_erreur = erreurs / total
    print(f"Taux de mauvais classement : {taux_erreur:.2%}")
    print("\nClassification report :")
    print(classification_report(y_test, y_pred))
    print("\n")

# ğŸ” Trouver le meilleur modÃ¨le
best_model_name = results_df.iloc[0]['Model']
print(f"\nğŸŒŸ Meilleur modÃ¨le selon F1-score : {best_model_name}")

# ğŸ” RÃ©cupÃ©rer l'objet du modÃ¨le
best_model = models[best_model_name]

# ğŸ”® PrÃ©dictions
y_best_pred = best_model.predict(X_test)

# ğŸ§¾ Matrice de confusion
cm = confusion_matrix(y_test, y_best_pred)
print("Matrice de confusion :")
print(cm)

# âš ï¸ Taux de mauvais classement
total = cm.sum()
correct = cm.diagonal().sum()
erreurs = total - correct
taux_erreur = erreurs / total
print(f"Taux de mauvais classement : {taux_erreur:.2%}")

# ğŸ“Œ Rapport complet
print("\nClassification report :")
print(classification_report(y_test, y_best_pred))
import joblib

# ğŸ” Sauvegarde dans le dossier choisi
chemin_sauvegarde = r"C:\INSEEDS\PROJET AFTER BAC\random_forest_orientation.pkl"
joblib.dump(best_model, chemin_sauvegarde)

print(f"âœ… ModÃ¨le sauvegardÃ© avec succÃ¨s dans : {chemin_sauvegarde}")


#___________________________________________


import streamlit as st
import joblib
import pandas as pd

# ğŸ” Charger le meilleur modÃ¨le
model = joblib.load(r"C:\INSEEDS\PROJET AFTER BAC\random_forest_orientation.pkl")

# ğŸ–¼ï¸ Interface
st.set_page_config(page_title="Orientation Post-Bac", layout="centered")
st.markdown("<h1 style='color: #004aad;'>ğŸ” PrÃ©diction de bon/mauvais choix de filiÃ¨re</h1>", unsafe_allow_html=True)
st.markdown("<h4>ğŸ’¡ Remplissez les caractÃ©ristiques de l'Ã©tudiant :</h4>", unsafe_allow_html=True)
kb = pd.read_excel("C:/INSEEDS/ORIEN.xlsx")
# ğŸ›ï¸ Menus dÃ©roulants
villes = sorted(kb['ville_post_bac'].unique())
ville = st.selectbox("Dans quelle ville Avez vous eu votre Bac?", options=villes)
filiÃ¨re= st.text_input("quelle filiÃ¨re aimeriez vous faire? ")
motif_filiÃ¨res = sorted(kb['motif_filiÃ¨re'].unique())
motif_filiÃ¨re = st.selectbox("pourquoi cette filiÃ¨re?", options=motif_filiÃ¨res)
preparation_choix = st.selectbox("ğŸ§  Avez-vous prÃ©parÃ© ce choix ?", ["Oui", "Non", "Un peu"])
Connaissance_filiÃ¨re = st.selectbox("ğŸ“– connaissez vous bien de la filiÃ¨re", ["Oui", "Non", "Un peu"])
conseil_par_pro = st.selectbox("ğŸ‘” Avez-vous Ã©tÃ© conseillÃ© par un professionnel ?", ["Oui", "Non"])
accÃ¨s_plateforme = st.selectbox("ğŸŒ Avez-vous utilisÃ© une plateforme dâ€™orientation ?", ["Oui", "Non"])
satisfaction_filiÃ¨re = st.selectbox("ğŸ˜Š Seriez-vous satisfait(e) de la filiÃ¨re ?", ["Oui", "Non"])
diplÃ´me = st.selectbox("ğŸ“ Avez-vous un diplÃ´me ?", ["Oui", "Non"])
employabilite = st.selectbox("ğŸ’¼ Pensez-vous que vous serez  ou Ãªtes employable ?", ["Oui", "Non"])
reconversion = st.selectbox("ğŸ”„ Souhaitez-vous vous reconvertir ?", ["Oui", "Non"])
referiez_mÃªme_choix = st.selectbox("ğŸ” Referiez-vous le mÃªme choix ?", ["Oui", "Non"])


# ğŸ¯ PrÃ©diction au clic
if st.button("ğŸ¯ PrÃ©dire le choix"):

    # ğŸ§¾ DonnÃ©es utilisateur
    input_data = pd.DataFrame({
        'preparation_choix': [preparation_choix],
        'Connaissance_filiÃ¨re': [Connaissance_filiÃ¨re],
        'conseil_par_pro': [conseil_par_pro],
        'accÃ¨s_plateforme': [accÃ¨s_plateforme],
        'satisfaction_filiÃ¨re': [satisfaction_filiÃ¨re],
        'diplÃ´me': [diplÃ´me],
        'employabilite': [employabilite],
        'reconversion': [reconversion],
        'referiez_mÃªme_choix': [referiez_mÃªme_choix]
    })

    # ğŸ” Encodage des valeurs
    conversion = {
        "Oui": 1, "Non": 0, "Un peu": 0.5
    }

    input_data = input_data.applymap(lambda val: conversion.get(val, val))  # sÃ©curise les valeurs non mappÃ©es

    # ğŸš¨ VÃ©rification
    if input_data.isnull().any().any():
        st.error("âš ï¸ Certaines rÃ©ponses ne sont pas reconnues. VÃ©rifie les valeurs ou Ã©largis le mapping.")
        st.write("DonnÃ©es reÃ§ues :", input_data)
    else:
        # ğŸ”® PrÃ©diction
        prediction = model.predict(input_data)[0]
        proba = model.predict_proba(input_data)[0]

        # ğŸ“¢ Affichage du rÃ©sultat
        if prediction == 0:
            st.error(f"âŒ Risque Ã©levÃ© : Mauvais choix possible.\nğŸ”» Score : {proba[0]*100:.2f}%")
        else:
            st.success(f"âœ… Bon choix dÃ©tectÃ© !\nğŸŸ¢ Score : {proba[1]*100:.2f}%")

        # ğŸ“Š Graphique
        st.markdown("### ğŸ“Š Score de prÃ©diction :")
        st.bar_chart({"Bon choix": [proba[1]*100], "Mauvais choix": [proba[0]*100]})


























